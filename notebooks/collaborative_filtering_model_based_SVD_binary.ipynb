{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time \n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from surprise import SVD, accuracy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://pass_culture:passq@localhost:5434/pass_culture?sslmode=prefer')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers rated by users from 0 to 5\n",
    "- Offers reserved: 5\n",
    "- Offers reserved but not consumed: 4\n",
    "- Offers reserved and canceled: 3\n",
    "- Favorite offers: 2\n",
    "- Offers clicked: 1\n",
    "- Offers ignored: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "offers_graded_from_0_to_5 = pd.read_csv('offers_graded_from_0_to_5.csv', sep = '\\t') \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers rated by users (binary notes)\n",
    "- Favorite offers, reserved and canceled, reserved and not consumed, reserved : 1\n",
    "- Offers ignored or just clicked : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_with_binary_notes = offers_graded_from_0_to_5\n",
    "offers_with_binary_notes['note'] = offers_with_binary_notes['note'].apply(lambda x: 0 if x==1 or x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', offers_with_binary_notes[offers_with_binary_notes['note']==0].shape[0], 'ratings 0')\n",
    "print('There are', offers_with_binary_notes[offers_with_binary_notes['note']==1].shape[0], 'ratings 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = offers_with_binary_notes['note'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / offers_with_binary_notes.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = 'Distribution of {} rates'.format(offers_with_binary_notes.shape[0]),\n",
    "              xaxis = dict(title = 'Rates'),\n",
    "              yaxis = dict(title = \"Number of rates\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the rates by types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_offers_per_category(dataframe_of_offers, category, total):\n",
    "    number_of_offers_per_type = pd.DataFrame(columns = [category, total])\n",
    "    number_of_offers_per_type[category] = dataframe_of_offers[category].value_counts().index\n",
    "    number_of_offers_per_type[total] = dataframe_of_offers[category].value_counts().array\n",
    "    return number_of_offers_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rates_per_type = compute_number_of_offers_per_category(offers_with_binary_notes, 'type', 'total')\n",
    "number_of_rates_0_par_type = compute_number_of_offers_per_category(offers_with_binary_notes[offers_with_binary_notes['note']==0], 'type','total_note0')\n",
    "number_of_rates_1_par_type = compute_number_of_offers_per_category(offers_with_binary_notes[offers_with_binary_notes['note']==1], 'type','total_note1')\n",
    "\n",
    "#We merge the three tables\n",
    "number_of_rates_per_type = number_of_rates_per_type.merge(number_of_rates_0_par_type, left_on='type', right_on='type')\n",
    "number_of_rates_per_type = number_of_rates_per_type.merge(number_of_rates_1_par_type, left_on='type', right_on='type')\n",
    "\n",
    "number_of_rates_per_type['pourcentage_note0'] = number_of_rates_per_type['total_note0'] * 100 / number_of_rates_per_type['total']\n",
    "number_of_rates_per_type['pourcentage_note1'] = number_of_rates_per_type['total_note1'] * 100 / number_of_rates_per_type['total']\n",
    "\n",
    "number_of_rates_per_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=number_of_rates_per_type['type'], \n",
    "           y=number_of_rates_per_type['total'],\n",
    "           name=\"Numbre of rates\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=number_of_rates_per_type['type'],\n",
    "               y=number_of_rates_per_type['pourcentage_note1'],\n",
    "               name=\"%tage rate 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#We add the title \n",
    "fig.update_layout(title_text='Distribution of rates per type')\n",
    "\n",
    "#Title axis x\n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y\n",
    "fig.update_yaxes(title_text=\"Number of rates\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Percentage of rate 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the rates by column 'isVirtual' : digital / physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_with_binary_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rates_per_isVirtual = compute_number_of_offers_per_category(offers_with_binary_notes, 'isVirtual','total')\n",
    "number_of_rate_0_per_isVirtual = compute_number_of_offers_per_category \\\n",
    "                                (offers_with_binary_notes[offers_with_binary_notes['note']==0], \\\n",
    "                                 'isVirtual','total_note0')\n",
    "number_of_rate_1_per_isVirtual = compute_number_of_offers_per_category( \\\n",
    "                                 offers_with_binary_notes[offers_with_binary_notes['note']==1], \\\n",
    "                                 'isVirtual','total_note1')\n",
    "\n",
    "#We merge the three tables \n",
    "number_of_rates_per_isVirtual = number_of_rates_per_isVirtual.merge(number_of_rate_0_per_isVirtual,\\\n",
    "                                                                  left_on='isVirtual', right_on='isVirtual')\n",
    "number_of_rates_per_isVirtual = number_of_rates_per_isVirtual.merge(number_of_rate_1_per_isVirtual,\\\n",
    "                                                                  left_on='isVirtual', right_on='isVirtual')\n",
    "\n",
    "number_of_rates_per_isVirtual['pourcentage_note0'] = number_of_rate_0_per_isVirtual['total_note0'] * 100 / number_of_rates_per_isVirtual['total']\n",
    "number_of_rates_per_isVirtual['pourcentage_note1'] = number_of_rate_1_per_isVirtual['total_note1'] * 100 / number_of_rates_per_isVirtual['total']\n",
    "\n",
    "number_of_rates_per_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=number_of_rates_per_isVirtual['isVirtual'], \n",
    "           y=number_of_rates_per_isVirtual['total'],\n",
    "           name=\"Number of rates\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=number_of_rates_per_isVirtual['isVirtual'],\n",
    "               y=number_of_rates_per_isVirtual['pourcentage_note1'],\n",
    "               name=\"%tage rate 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#We add the title \n",
    "fig.update_layout(title_text='Distribution of rates per isVirtual')\n",
    "\n",
    "#Title axis x\n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y\n",
    "fig.update_yaxes(title_text=\"Number of rates\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Percentage of rate 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD : Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(offers_with_binary_notes[['user_id', 'offer_id', 'note']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, train_size=0.75, test_size=0.25)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "algo = SVD(n_factors=100)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"debut = time.time()\n",
    "\n",
    "filename = 'train_100_binaire_avant_reequilibrage.sav'\n",
    "pickle.dump(algo, open(filename, 'wb'))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'train_100_binaire_avant_reequilibrage.sav'\n",
    "algo = pickle.load(open(filename, 'rb')) \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "predictions_of_the_grades = algo.test(testset)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"debut = time.time()\n",
    "\n",
    "filename = 'prediction_1000_binaire_avant_reequilibrage.sav'\n",
    "pickle.dump(predictions_of_the_grades, open(filename, 'wb'))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'prediction_1000_binaire_avant_reequilibrage.sav'\n",
    "predictions_of_the_grades = pickle.load(open(filename, 'rb')) \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_of_the_grades = pd.DataFrame(predictions_of_the_grades)\n",
    "predictions_of_the_grades.columns = ['user_id','offer_id', 'note', 'score', 'details']\n",
    "del predictions_of_the_grades['details']\n",
    "predictions_of_the_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = predictions_of_the_grades['score'].apply(round).value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / predictions_of_the_grades.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = 'Prediction : Distribution of {} rates'.format(predictions_of_the_grades.shape[0]),\n",
    "              xaxis = dict(title = 'Rates'),\n",
    "              yaxis = dict(title = \"Number of rates\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get the types of offers and the isVirtual column\n",
    "predictions_of_the_grades = predictions_of_the_grades.merge(offers_with_binary_notes, \\\n",
    "                                                            left_on=['user_id', 'offer_id','note'], \\\n",
    "                                                            right_on=['user_id', 'offer_id','note'])\n",
    "predictions_of_the_grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction : Distribution of rates per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rates_per_type_in_the_prediction = compute_number_of_offers_per_category(predictions_of_the_grades, \\\n",
    "                                                                                   'type', 'total')\n",
    "number_of_rate_0_per_type_in_the_prediction = compute_number_of_offers_per_category(predictions_of_the_grades\\\n",
    "                                              [predictions_of_the_grades['note']==0], 'type', 'total_note0')\n",
    "\n",
    "number_of_rate_1_per_type_in_the_prediction = compute_number_of_offers_per_category(predictions_of_the_grades\\\n",
    "                                              [predictions_of_the_grades['note']==1], 'type', 'total_note1')\n",
    "\n",
    "#We merge the three tables \n",
    "number_of_rates_per_type_in_the_prediction = number_of_rates_per_type_in_the_prediction.merge(\\\n",
    "                                             number_of_rate_0_per_type_in_the_prediction, \\\n",
    "                                             left_on='type', right_on='type')\n",
    "number_of_rates_per_type_in_the_prediction = number_of_rates_per_type_in_the_prediction.merge(\\\n",
    "                                             number_of_rate_1_per_type_in_the_prediction, \\\n",
    "                                             left_on='type', right_on='type')\n",
    "\n",
    "number_of_rates_per_type_in_the_prediction['pourcentage_note0'] = number_of_rates_per_type_in_the_prediction\\\n",
    "                                                                  ['total_note0'] * 100 / \\\n",
    "                                                                  number_of_rates_per_type_in_the_prediction['total']\n",
    "number_of_rates_per_type_in_the_prediction['pourcentage_note1'] = number_of_rates_per_type_in_the_prediction\\\n",
    "                                                                  ['total_note1'] * 100 / \\\n",
    "                                                                  number_of_rates_per_type_in_the_prediction['total']\n",
    "\n",
    "number_of_rates_per_type_in_the_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=number_of_rates_per_type_in_the_prediction['type'], \n",
    "           y=number_of_rates_per_type_in_the_prediction['total'],\n",
    "           name=\"Number of rates\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=number_of_rates_per_type_in_the_prediction['type'],\n",
    "               y=number_of_rates_per_type_in_the_prediction['pourcentage_note1'],\n",
    "               name=\"%tage rate 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#We add the title \n",
    "fig.update_layout(title_text='Prediction : Distribution of rates per type')\n",
    "\n",
    "#Title axis x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y\n",
    "fig.update_yaxes(title_text=\"Number of rates\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Percentage of rate 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction : Distribution of rates per isVirtual : digital/physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rates_per_isVirtual_in_the_prediction = compute_number_of_offers_per_category(\\\n",
    "                                                  predictions_of_the_grades, 'isVirtual', 'total')\n",
    "number_of_rate_0_per_isVirtual_in_the_prediction = compute_number_of_offers_per_category(predictions_of_the_grades\\\n",
    "                                                   [predictions_of_the_grades['note']==0], \\\n",
    "                                                   'isVirtual', 'total_note0')\n",
    "number_of_rate_1_per_isVirtual_in_the_prediction = compute_number_of_offers_per_category(predictions_of_the_grades\\\n",
    "                                                   [predictions_of_the_grades['note']==1], \\\n",
    "                                                   'isVirtual', 'total_note1')\n",
    "#We merge the three tables \n",
    "number_of_rates_per_isVirtual_in_the_prediction = number_of_rates_per_isVirtual_in_the_prediction.merge(\\\n",
    "                                                  number_of_rate_0_per_isVirtual_in_the_prediction, \\\n",
    "                                                  left_on='isVirtual', right_on='isVirtual')\n",
    "number_of_rates_per_isVirtual_in_the_prediction = number_of_rates_per_isVirtual_in_the_prediction.merge(\\\n",
    "                                                  number_of_rate_1_per_isVirtual_in_the_prediction, \\\n",
    "                                                  left_on='isVirtual', right_on='isVirtual')\n",
    "\n",
    "number_of_rates_per_isVirtual_in_the_prediction['pourcentage_note0'] = number_of_rates_per_isVirtual_in_the_prediction\\\n",
    "                                 ['total_note0'] * 100 / number_of_rates_per_isVirtual_in_the_prediction['total']\n",
    "number_of_rates_per_isVirtual_in_the_prediction['pourcentage_note1'] = number_of_rates_per_isVirtual_in_the_prediction\\\n",
    "                                ['total_note1'] * 100 / number_of_rates_per_isVirtual_in_the_prediction['total']\n",
    "\n",
    "number_of_rates_per_isVirtual_in_the_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=number_of_rates_per_isVirtual_in_the_prediction['isVirtual'], \n",
    "           y=number_of_rates_per_isVirtual_in_the_prediction['total'],\n",
    "           name=\"Number of rates\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=number_of_rates_per_isVirtual_in_the_prediction['isVirtual'],\n",
    "               y=number_of_rates_per_isVirtual_in_the_prediction['pourcentage_note1'],\n",
    "               name=\"%tage rate 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#We add the title \n",
    "fig.update_layout(title_text='Prediction : Distribution of rates per isVirtual')\n",
    "\n",
    "#Title axis x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y \n",
    "fig.update_yaxes(title_text=\"Number of rates\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Percentage of rate 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "- Confusion matrix\n",
    "- Accuracy / Recall / Precision / F1\n",
    "- ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_of_the_grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    data = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_pred), index=np.unique(y_true))\n",
    "    df_cm.index.name = 'Actual values'\n",
    "    df_cm.columns.name = 'Predicted values'\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sn.set(font_scale=1.4)\n",
    "    akws = {\"ha\": 'center', \"va\": 'center'}\n",
    "    sn.heatmap(df_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", annot_kws=akws, center=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predictions_of_the_grades['note']\n",
    "y_pred = predictions_of_the_grades['score'].apply(round)\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy / Recall / Precision / F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_recall_precision_f1(y_true, y_pred):\n",
    "    print('accuracy = ', accuracy_score(y_true, y_pred))\n",
    "    print('recall = ', recall_score(y_true, y_pred))\n",
    "    print('precision = ', precision_score(y_true, y_pred))\n",
    "    print('F1 = ', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predictions_of_the_grades['note']\n",
    "y_pred = predictions_of_the_grades['score'].apply(round)\n",
    "accuracy_recall_precision_f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred):\n",
    "    # ROC curve\n",
    "    false_positive_rate = dict()\n",
    "    true_positive_rate = dict()\n",
    "    roc_auc = dict()\n",
    "    number_of_classes = 2\n",
    "\n",
    "    for i in range(number_of_classes):\n",
    "        false_positive_rate[i], true_positive_rate[i], _ = roc_curve(y_true, y_pred)\n",
    "        roc_auc[i] = auc(false_positive_rate[i], true_positive_rate[i])\n",
    "\n",
    "    # Compute roc curve 'micro' and AUC\n",
    "    false_positive_rate[\"micro\"], true_positive_rate[\"micro\"], _ = roc_curve(y_true.ravel(),\n",
    "                                                                             y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(false_positive_rate[\"micro\"], true_positive_rate[\"micro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "\n",
    "    plt.plot(false_positive_rate[\"micro\"], true_positive_rate[\"micro\"], color='darkorange', lw=lw,\n",
    "             label='AUC = %0.2f' % roc_auc[\"micro\"])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "    plt.xlabel('Taux de faux positifs')\n",
    "    plt.ylabel('Taux de vrais positifs')\n",
    "    plt.title('Courbe ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predictions_of_the_grades['note']\n",
    "y_pred = predictions_of_the_grades['score']\n",
    "plot_roc_curve(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_thresholds_to_have_a_good_recall(predictions_of_the_grades):\n",
    "    # We are looking for a compromise between the rate of true positives and the rate of false positives\n",
    "    # The optimal threshold would be when true_positive_rate is high and false_positive_rate is low, ie:\n",
    "    # true_positive_rate - (1-false-positive-rate) is zero or close to zero\n",
    "\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(predictions_of_the_grades['note'],\n",
    "                                                                    predictions_of_the_grades['score'])\n",
    "\n",
    "    i = np.arange(len(true_positive_rate))\n",
    "    roc = pd.DataFrame({'false_positive_rate': pd.Series(false_positive_rate, index=i),\n",
    "                        'true_positive_rate': pd.Series(true_positive_rate, index=i),\n",
    "                        '1-false_positive_rate': pd.Series(1 - false_positive_rate, index=i),\n",
    "                        'true_positive_rate-(1-false_positive_rate)': pd.Series(true_positive_rate - (1 - false_positive_rate), index=i),\n",
    "                        'thresholds': pd.Series(thresholds, index=i)})\n",
    "\n",
    "    # Plot true_positive_rate vs 1-false_positive_rate\n",
    "    fig, ax = pl.subplots()\n",
    "    pl.plot(roc['true_positive_rate'], color='blue', label='TVP')\n",
    "    pl.plot(roc['1-false_positive_rate'], color='red', label='1-false_positive_rate')\n",
    "    pl.xlabel('1-false_positive_rate')\n",
    "    pl.ylabel('true_positive_rate')\n",
    "    pl.title('ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    ax.set_xticklabels([])\n",
    "    plt.show()\n",
    "\n",
    "    roc = roc.iloc[(roc['true_positive_rate-(1-false_positive_rate)'] - 0).abs().argsort()[:1]]\n",
    "\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = find_the_thresholds_to_have_a_good_recall(predictions_of_the_grades)\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We change the threshold of the prections by the new threshold\n",
    "predictions_of_the_grades['score_avec_seuil'] = predictions_of_the_grades['score'].apply(lambda x: 1 \\\n",
    "                                                if x > roc['thresholds'].values[0] else 0)\n",
    "\n",
    "y_true = predictions_of_the_grades['note']\n",
    "y_pred = predictions_of_the_grades['score_avec_seuil']\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics\n",
    "y_true = predictions_of_the_grades['note']\n",
    "y_pred = predictions_of_the_grades['score_avec_seuil']\n",
    "accuracy_recall_precision_f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We filter the offers so as to keep only the recommendable offers, that is to say\n",
    "- those in the discovery_view table\n",
    "- those who are in a department close to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_offers = pd.read_sql_query(\"\"\"SELECT * FROM discovery_view\"\"\", connection)\n",
    "print('There are', recommendable_offers['id'].nunique(), 'recommendable offers')\n",
    "recommendable_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split them into digital and physical offers \n",
    "- The digital offers will be recommended to all the users \n",
    "- The physical offers will be recommended depending on the postal code of the user and the offer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_digital_offers = recommendable_offers[recommendable_offers['url'].notna()]\n",
    "recommendable_digital_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_sql_query(\"\"\"SELECT \"user\".\"id\" as user_id FROM \"user\" \"\"\", connection)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_digital_offers['key'] = 1\n",
    "users['key'] = 1\n",
    "recommendable_digital_offers = recommendable_digital_offers.merge(users, on='key').drop('key',axis=1)\n",
    "recommendable_digital_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_physical_offers = recommendable_offers[recommendable_offers['url'].isna()]\n",
    "recommendable_physical_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add the offers's postal code \n",
    "venue = pd.read_sql_query(\"\"\"SELECT \"id\" as \"venueId\",  \"departementCode\" as offer_pc FROM \"venue\" \"\"\", connection)\n",
    "\n",
    "recommendable_physical_offers = recommendable_physical_offers.merge(venue, left_on='venueId', right_on='venueId')\n",
    "\n",
    "recommendable_physical_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_pc = pd.read_sql_query(\"\"\"SELECT \"user\".\"id\" as user_id, \"departementCode\" as user_pc FROM \"user\" \"\"\", connection)\n",
    "users_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère la liste des départements \n",
    "nearby_departments = {\n",
    "    '08': ['02', '08', '51', '55', '59'],\n",
    "    '22': ['22', '29', '35', '56'],\n",
    "    '25': ['21', '25', '39', '68', '70', '71', '90'],\n",
    "    '29': ['22', '35', '29', '56'],\n",
    "    '34': ['11', '12', '13', '30', '31', '34', '48', '66', '81', '84'],\n",
    "    '35': ['22', '29', '35', '44', '49', '50', '53', '56'],\n",
    "    '56': ['22', '29', '35', '44', '56'],\n",
    "    '58': ['03', '18', '21', '45', '58', '71', '89'],\n",
    "    '67': ['54', '55', '57', '67', '68', '88'],\n",
    "    '71': ['01', '03', '21', '39', '42', '58', '69', '71'],\n",
    "    '84': ['04', '07', '13', '26', '30', '83', '84'],\n",
    "    '93': ['75', '77', '78', '91', '92', '93', '94', '95'],\n",
    "    '94': ['75', '77', '78', '91', '92', '93', '94', '95'],\n",
    "    '97': ['97', '971', '972', '973'],\n",
    "    '973': ['97', '971', '972', '973'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On le transforme en dataframe\n",
    "keys = []\n",
    "values = []\n",
    "for key, value_list in nearby_departments.items():\n",
    "    keys += [key] * len(value_list)\n",
    "    values += value_list\n",
    "    \n",
    "    \n",
    "nearby_departments = pd.DataFrame({'user_pc' : keys, 'offer_pc' : values})\n",
    "nearby_departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_physical_offers = recommendable_physical_offers.merge(nearby_departments, left_on='offer_pc', \\\n",
    "                                                                    right_on='offer_pc')\n",
    "recommendable_physical_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendable_physical_offers = recommendable_physical_offers.merge(users_pc, left_on='user_pc', \\\n",
    "                                                                    right_on='user_pc')\n",
    "recommendable_physical_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe of all the recommendable offers to all the users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "recommendable_offers_to_all_the_users = pd.concat([recommendable_physical_offers, recommendable_digital_offers], sort=False)\n",
    "recommendable_offers_to_all_the_users\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the users/offers from Bretagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "bretagne = ['22', '29', '35', '56']\n",
    "recommendable_offers_to_all_the_users_in_bretagne = recommendable_offers_to_all_the_users[recommendable_offers_to_all_the_users['offer_pc'].isin(bretagne)]\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 25549\n",
    "recommendable_offers_for_one_user = recommendable_offers_to_all_the_users[recommendable_offers_to_all_the_users['user_id'] == user_id]\n",
    "recommendable_offers_for_one_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "offers_recommended_to_a_user = []\n",
    "\n",
    "for _, row in recommendable_offers_for_one_user.iterrows():\n",
    "    offers_recommended_to_a_user.append(algo.predict(user_id, row.id))\n",
    "\n",
    "offers_recommended_to_a_user = pd.DataFrame(data = offers_recommended_to_a_user, columns = ['user_id', 'offer_id', 'real_rate', 'score', 'details'])\n",
    "offers_recommended_to_a_user = offers_recommended_to_a_user.sort_values(by='score', ascending=False)\n",
    "    \n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user.to_csv('../offers_recommended_to_a_user.csv', index=False, sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers = pd.read_sql_query(\"\"\"SELECT id as offer_id, name, type FROM offer \"\"\", connection)\n",
    "offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user = offers_recommended_to_a_user.merge(offers, right_on='offer_id', left_on='offer_id')\n",
    "offers_recommended_to_a_user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
