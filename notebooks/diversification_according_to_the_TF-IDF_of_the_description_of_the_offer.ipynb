{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://pass_culture:passq@localhost:5434/pass_culture?sslmode=prefer')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversification of offers according to the TF-IDF of their description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the recommended offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user = pd.read_csv('../offers_recommended_to_a_user.csv', sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user.drop_duplicates(inplace=True) \n",
    "offers_recommended_to_a_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the description of the offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_with_the_description = pd.read_sql_query(\"\"\"SELECT id as offer_id, description, type FROM offer \"\"\", connection)\n",
    "offers_with_the_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user = offers_recommended_to_a_user.merge(offers_with_the_description, right_on=\"offer_id\", left_on=\"offer_id\")\n",
    "offers_recommended_to_a_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_recommended_to_a_user.dropna(subset=['description'], inplace=True) \n",
    "offers_recommended_to_a_user.reset_index(drop=True, inplace=True)\n",
    "offers_recommended_to_a_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', \\\n",
    "                     stop_words=get_stop_words('french'), \\\n",
    "                     strip_accents = 'ascii', \\\n",
    "                     lowercase = True)\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(offers_recommended_to_a_user['description'])\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the similarity between the offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Linear kernel = cosine_similarity quand on a une très grande quantité de données (linear kernel est plus rapide)\n",
    "cosinus_similarity = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_of_the_offer_with_offers_using_the_index(index_of_the_offer, index_of_the_other_offers, similarity_matrix):\n",
    "     return np.mean(similarity_matrix[index_of_the_offer, index_of_the_other_offers])\n",
    "    \n",
    "def compute_similarity_for_each_offer(most_relevant_offers_recommended_to_a_user):\n",
    "    for index, row in most_relevant_offers_recommended_to_a_user.iterrows():\n",
    "        other_offers = most_relevant_offers_recommended_to_a_user[most_relevant_offers_recommended_to_a_user['index'] != most_relevant_offers_recommended_to_a_user.loc[index, 'index']]\n",
    "        index_of_the_other_offers = other_offers['index'].values  \n",
    "        similarite = compute_similarity_of_the_offer_with_offers_using_the_index(most_relevant_offers_recommended_to_a_user.loc[index, 'index'], index_of_the_other_offers, cosinus_similarity)\n",
    "        most_relevant_offers_recommended_to_a_user.loc[index, 'similarite'] = similarite\n",
    "    return most_relevant_offers_recommended_to_a_user\n",
    "\n",
    "def get_real_index_of_the_offer_with_the_highest_similarity(dataframe_of_most_relevant_offers):\n",
    "    offer_with_the_highest_similarity = dataframe_of_most_relevant_offers[dataframe_of_most_relevant_offers['similarite'] == dataframe_of_most_relevant_offers['similarite'].max()]\n",
    "    index_of_the_offer_with_the_highest_similarity = offer_with_the_highest_similarity['index'].values\n",
    "    return index_of_the_offer_with_the_highest_similarity\n",
    "\n",
    "def get_index_of_the_offer_with_the_highest_similarity(dataframe_of_most_relevant_offers):\n",
    "    offer_with_the_highest_similarity = dataframe_of_most_relevant_offers[dataframe_of_most_relevant_offers['similarite'] == dataframe_of_most_relevant_offers['similarite'].max()]\n",
    "    index_of_the_offer_with_the_highest_similarity = offer_with_the_highest_similarity['index'].values\n",
    "    index_of_the_offer_with_the_highest_similarity = dataframe_of_most_relevant_offers[dataframe_of_most_relevant_offers['index'] == index_of_the_offer_with_the_highest_similarity[0]].index[0]\n",
    "    return index_of_the_offer_with_the_highest_similarity\n",
    "\n",
    "def get_index_to_exchange_in_the_least_relevant_offers(dataframe_of_least_relevant_offers, dataframe_of_most_relevant_offers, real_index_of_the_offer_with_the_highest_similarity, index_of_the_offer_with_the_highest_similarity, similarity_matrix):\n",
    "    value_of_the_highest_similarity = dataframe_of_most_relevant_offers.loc[index_of_the_offer_with_the_highest_similarity, 'similarite']\n",
    "    most_relevant_offers_without_the_offer_with_the_highest_similarity = dataframe_of_most_relevant_offers[dataframe_of_most_relevant_offers['index'] != real_index_of_the_offer_with_the_highest_similarity[0]]\n",
    "    index_of_the_most_relevant_offers_without_the_offer_with_the_highest_similarity = most_relevant_offers_without_the_offer_with_the_highest_similarity['index'].values\n",
    "    for i, row in dataframe_of_least_relevant_offers.iterrows():\n",
    "        similarity_of_offer_in_the_least_relevant_offers = compute_similarity_of_the_offer_with_offers_using_the_index(row['index'], index_of_the_most_relevant_offers_without_the_offer_with_the_highest_similarity, similarity_matrix)\n",
    "        if similarity_of_offer_in_the_least_relevant_offers < value_of_the_highest_similarity:\n",
    "            dataframe_of_least_relevant_offers.loc[dataframe_of_least_relevant_offers['index'] == row['index'], 'similarite'] = similarity_of_offer_in_the_least_relevant_offers\n",
    "            return row['index']\n",
    "        \n",
    "def exchange_offers_from_one_df_to_another(df1, df2, index1, index2):\n",
    "    df1.loc[index1] = df2.loc[index2]\n",
    "    return df1\n",
    "\n",
    "def drop_the_exchange_offer_from_the_least_relevant_offers(dataframe_of_offers, index_of_offer_to_drop):\n",
    "    dataframe_of_offers.drop(index_of_offer_to_drop, axis=0, inplace=True)\n",
    "    return dataframe_of_offers\n",
    "\n",
    "def compute_combination_of_k_among_n(k, n):\n",
    "    return math.factorial(n) / (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "def compute_similarity_of_the_set(df1, similarity_matrix):\n",
    "    similarity_of_the_set = 0. \n",
    "    for i, row in df1.iterrows():\n",
    "        for j in range(i+1, len(df1)):\n",
    "            similarity_of_the_set += (similarity_matrix[df1.loc[i, 'index'], df1.loc[j, 'index']])\n",
    "    similarity_of_the_set = similarity_of_the_set / compute_combination_of_k_among_n(2, K)\n",
    "    return similarity_of_the_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_of_the_name_of_all_the_types(df):\n",
    "    number_of_offers_per_type = pd.DataFrame()\n",
    "    number_of_offers_per_type['type'] = df['type'].value_counts().index\n",
    "    return number_of_offers_per_type\n",
    "\n",
    "def replace_dot_with_a_dash_in_the_column_type(df):\n",
    "    list_of_types = []\n",
    "    for types in df['type']:\n",
    "        list_of_types.append(str(types).replace(\".\", \"_\"))\n",
    "    df['type'] = list_of_types\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_offers_per_category(dataframe_of_offers, category, total):\n",
    "    number_of_offers_per_type = pd.DataFrame(columns = [category, total])\n",
    "    number_of_offers_per_type[category] = dataframe_of_offers[category].value_counts().index\n",
    "    number_of_offers_per_type[total] = dataframe_of_offers[category].value_counts().array\n",
    "    return number_of_offers_per_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We look at the TF-IDF of the words in the description of the offers that we recommend to a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 40\n",
    "most_relevant_offers_recommended_to_a_user = offers_recommended_to_a_user[0:K]\n",
    "most_relevant_offers_recommended_to_a_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_of_the_offers = pd.DataFrame(columns = np.arange(len(most_relevant_offers_recommended_to_a_user)))\n",
    "for i, row in most_relevant_offers_recommended_to_a_user.iterrows():\n",
    "    id_offre = row['offer_id']\n",
    "    index = i\n",
    "    tfidf_de_loffre = tfidf_matrix[index]\n",
    "\n",
    "    #On met les tf-idf dans un dataframe\n",
    "    df_tfidf = pd.DataFrame(tfidf_de_loffre.T.todense(), index = vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "    df_tfidf = df_tfidf.sort_values(by=[\"tfidf\"], ascending=False)  \n",
    "    df_tfidf = df_tfidf.head(10)\n",
    "    tfidf_of_the_offers[i] = df_tfidf.index\n",
    "    tfidf_of_the_offers = tfidf_of_the_offers.rename(columns={i: row['type']})\n",
    "\n",
    "tfidf_of_the_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do K exchanges to diversify the whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "K = 40\n",
    "N = len(offers_recommended_to_a_user)\n",
    "\n",
    "offers_recommended_to_a_user['index'] = offers_recommended_to_a_user.index\n",
    "most_relevant_offers_recommended_to_a_user = offers_recommended_to_a_user[0:K]\n",
    "least_relevant_offers_recommended_to_a_user = offers_recommended_to_a_user[K+1:N]\n",
    "\n",
    "sum_of_the_score = []\n",
    "similarity_of_the_set = []\n",
    "\n",
    "number_of_offers_per_type = create_dataframe_of_the_name_of_all_the_types(offers_recommended_to_a_user)\n",
    "number_of_offers_per_type = replace_dot_with_a_dash_in_the_column_type(number_of_offers_per_type)\n",
    "\n",
    "number_of_exchanges = 40\n",
    "\n",
    "for i in range(0,number_of_exchanges):\n",
    "    \n",
    "    sum_of_the_score.append(sum(most_relevant_offers_recommended_to_a_user['score'])/K)\n",
    "\n",
    "    most_relevant_offers_recommended_to_a_user = compute_similarity_for_each_offer(most_relevant_offers_recommended_to_a_user)\n",
    "    \n",
    "    real_index_of_the_offer_with_the_highest_similarity = get_real_index_of_the_offer_with_the_highest_similarity(most_relevant_offers_recommended_to_a_user)\n",
    "    \n",
    "    index_of_the_offer_with_the_highest_similarity = get_index_of_the_offer_with_the_highest_similarity(most_relevant_offers_recommended_to_a_user)\n",
    "    \n",
    "    index_to_exchange_in_the_least_relevant_offers = get_index_to_exchange_in_the_least_relevant_offers(least_relevant_offers_recommended_to_a_user, most_relevant_offers_recommended_to_a_user, real_index_of_the_offer_with_the_highest_similarity, index_of_the_offer_with_the_highest_similarity, cosinus_similarity)  \n",
    "    \n",
    "    if index_to_exchange_in_the_least_relevant_offers is not None : \n",
    "        \n",
    "        most_relevant_offers_recommended_to_a_user = exchange_offers_from_one_df_to_another(most_relevant_offers_recommended_to_a_user, least_relevant_offers_recommended_to_a_user, index_of_the_offer_with_the_highest_similarity, index_to_exchange_in_the_least_relevant_offers)\n",
    "    \n",
    "        least_relevant_offers_recommended_to_a_user = drop_the_exchange_offer_from_the_least_relevant_offers(least_relevant_offers_recommended_to_a_user, index_to_exchange_in_the_least_relevant_offers)\n",
    "    \n",
    "        similarity_of_the_set.append(compute_similarity_of_the_set(most_relevant_offers_recommended_to_a_user, cosinus_similarity))\n",
    "        \n",
    "        number_of_offers_per_type_for_this_iteration = compute_number_of_offers_per_category(most_relevant_offers_recommended_to_a_user, 'type', i)\n",
    "        number_of_offers_per_type_for_this_iteration = replace_dot_with_a_dash_in_the_column_type(number_of_offers_per_type_for_this_iteration)\n",
    "        \n",
    "        number_of_offers_per_type = number_of_offers_per_type.merge(number_of_offers_per_type_for_this_iteration, how='outer', left_on='type', right_on='type')\n",
    "        \n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average scores after each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(number_of_exchanges)\n",
    "y = sum_of_the_score\n",
    "\n",
    "layout = dict(title = \"Average scores after each exchange \",\n",
    "              xaxis = dict(title = \"Number of exchanges\"),\n",
    "              yaxis = dict(title = \"Average scores\"))\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of the set after each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(number_of_exchanges)\n",
    "y = similarity_of_the_set\n",
    "\n",
    "layout = dict(title = \"Similarity after each exchange\",\n",
    "              xaxis = dict(title = \"Number of exchanges\"),\n",
    "              yaxis = dict(title = \"Similarity\"))\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best/Worst case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best case\n",
    "- We take 40 offers at random from the discovery view\n",
    "- We calculate the similarity of the set\n",
    "- We do this 1000 times and we get the smallest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_view = pd.read_sql_query(\"\"\"SELECT offer.id as offer_id, offer.description, offer.type \n",
    "                                      FROM discovery_view \n",
    "                                      INNER JOIN offer \n",
    "                                      ON offer.id = discovery_view.id\n",
    "                                    \"\"\", connection)\n",
    "discovery_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_view.dropna(subset = ['description'], inplace=True) \n",
    "discovery_view.reset_index(drop=True, inplace=True)\n",
    "discovery_view['index'] = discovery_view.index\n",
    "discovery_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "vectorizer_discovery_view = TfidfVectorizer(analyzer='word', \\\n",
    "                     stop_words=get_stop_words('french'), \\\n",
    "                     strip_accents = 'ascii', \\\n",
    "                     lowercase = True)\n",
    "\n",
    "tfidf_matrix_discovery_view = vectorizer_discovery_view.fit_transform(discovery_view['description'])\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Linear kernel = cosine_similarity quand on a une très grande quantité de données (linear kernel est plus rapide)\n",
    "cosinus_similarite_discovery_view = linear_kernel(tfidf_matrix_discovery_view, tfidf_matrix_discovery_view)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "from random import sample    \n",
    "from random import shuffle \n",
    "\n",
    "similarite_ensemble_best_case = []\n",
    "\n",
    "for i in range(1000):\n",
    "    offers_sample = discovery_view.sample(K)\n",
    "    offers_sample.reset_index(drop=True, inplace=True)\n",
    "    similarite_ensemble_best_case.append(compute_similarity_of_the_set(offers_sample, cosinus_similarite_discovery_view))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst case\n",
    "### In the worst case, all our offers \"are similar\" and therefore there is no diversification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We get an offer randomly\n",
    "- We add the offer that has the greatest similarity with the first\n",
    "- We add the offer that has the greatest similarity with the second\n",
    "- And so on until we have the 40 offers\n",
    "- We calculate the similarity of the set\n",
    "- We do this 1000 times then we recover the value of the greatest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_most_similar_offers_by_starting_with_a_random_offer():\n",
    "    most_similar_offers = discovery_view.sample(1)\n",
    "    most_similar_offers.reset_index(drop=True, inplace=True)\n",
    "    for i in range(49):\n",
    "        index_of_the_offer = most_similar_offers['index'][most_similar_offers.index[-1]]\n",
    "        cosinus_similarite_discovery_view[index_of_the_offer][index_of_the_offer] = 0 # Parce que c'est égal à 1 et quand on va chercher le max ca va prendre cette offre \n",
    "        index_of_the_following_offer = np.argmax(cosinus_similarite_discovery_view[index_of_the_offer])\n",
    "        cosinus_similarite_discovery_view[index_of_the_offer][index_of_the_following_offer] = 0 # Il faut aussi l'enlever de l'offre qu'on ajoute sinon ils vont se renvoyer la balle \n",
    "        cosinus_similarite_discovery_view[index_of_the_following_offer][index_of_the_offer] = 0 # Il faut aussi l'enlever de l'offre qu'on ajoute sinon ils vont se renvoyer la balle \n",
    "        most_similar_offers = most_similar_offers.append(discovery_view[discovery_view['index'] == index_of_the_following_offer], ignore_index=True)\n",
    "    return most_similar_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "from random import sample    \n",
    "from random import shuffle \n",
    "\n",
    "similarite_ensemble_worst_case = []\n",
    "\n",
    "for i in range(1000):\n",
    "    most_similar_offers = get_the_most_similar_offers_by_starting_with_a_random_offer()\n",
    "    similarite_ensemble_worst_case.append(compute_similarity_of_the_set(most_similar_offers, cosinus_similarite_discovery_view))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of the similarity of the set with the best and worst case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(70)\n",
    "y = similarity_of_the_set\n",
    "\n",
    "layout = dict(title = \"Similarity after each exchange of offers\",\n",
    "              xaxis = dict(title = \"Number of exchanges\"),\n",
    "              yaxis = dict(title = \"Similarity\"))\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines'))\n",
    "\n",
    "# Line Horizontal --> Worst case\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "            x0=0,\n",
    "            y0=max(similarite_ensemble_best_case),\n",
    "            x1=number_of_exchanges,\n",
    "            y1=max(similarite_ensemble_best_case),\n",
    "            line=dict(\n",
    "                color=\"LightSeaGreen\",\n",
    "                width=4,\n",
    "                dash=\"dashdot\",\n",
    "            ),\n",
    ")\n",
    "\n",
    "# Line Horizontal --> Best case\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "            x0=0,\n",
    "            y0=min(similarite_ensemble_best_case),\n",
    "            x1=number_of_exchanges,\n",
    "            y1=min(similarite_ensemble_best_case),\n",
    "            line=dict(\n",
    "                color=\"LightSeaGreen\",\n",
    "                width=4,\n",
    "                dash=\"dashdot\",\n",
    "            ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of types after diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_offers_per_type.dropna(axis=0, how='all', subset = range(0, 40), inplace=True)\n",
    "number_of_offers_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_offers_per_type.to_csv('number_of_offers_per_type_in_diversification_TF_IDF.csv', index=False, sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iteration = 40\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "            x = number_of_offers_per_type['type'], \n",
    "            y = number_of_offers_per_type[0],\n",
    "            text = number_of_offers_per_type[0],\n",
    "            textposition = 'auto',\n",
    "        )])\n",
    "\n",
    "#We add the title\n",
    "fig.update_layout(title_text='Distribution of the types before diversification')\n",
    "\n",
    "#Title axis x\n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y\n",
    "fig.update_yaxes(title_text=\"Number of offers\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iteration = 40\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "            x = number_of_offers_per_type['type'], \n",
    "            y = number_of_offers_per_type[15],\n",
    "            text = number_of_offers_per_type[15],\n",
    "            textposition = 'auto',\n",
    "        )])\n",
    "\n",
    "#We add the title\n",
    "fig.update_layout(title_text='Distribution of the types after diversification')\n",
    "\n",
    "#Title axis x\n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Title axis y\n",
    "fig.update_yaxes(title_text=\"Number of offers\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"simple_white\"\n",
    "\n",
    "data = pd.read_csv('number_of_offers_per_type_in_diversification_TF_IDF.csv', sep = '\\t')\n",
    "\n",
    "#Documentation for make_bar_chart_function\n",
    "'''\n",
    "    This function can be used with a dataset whose one column\n",
    "    is categorical for which bar chart is required and other columns\n",
    "    are various years which will serve as a frame rate.\n",
    "'''\n",
    "\n",
    "def make_bar_chart(dataset, categrical_col, start_year, end_year, title , frame_rate = 3):\n",
    "    names = dataset[categrical_col]\n",
    "    yvals = dataset.loc[:,start_year]\n",
    "    def get_rgb_vals():\n",
    "        r = np.random.randint(1,255)\n",
    "        g = np.random.randint(1,255)\n",
    "        b = np.random.randint(1,255)\n",
    "        return [r,g,b]\n",
    "    colors = []\n",
    "    for i in range(len(names)):\n",
    "        c = get_rgb_vals()\n",
    "        colors.append(\"rgb(\" + str(c[0]) + \",\"+ str(c[1]) + \",\"+ str(c[2]) + \")\")\n",
    "       \n",
    "    def get_top_10(d):\n",
    "        df = pd.DataFrame({\"names\":names, \"pop\":d, \"color\":colors})\n",
    "        #data = df.sort_values(by = \"pop\").iloc[-15:,]\n",
    "        return df\n",
    "\n",
    "    listOfFrames = []\n",
    "    for i in range(int(start_year),int(end_year)+1,frame_rate):\n",
    "        d = data.loc[:,str(i)]\n",
    "        pdata = get_top_10(d)\n",
    "        listOfFrames.append(go.Frame(data = [go.Bar(x = pdata[\"names\"], y = pdata[\"pop\"],\n",
    "                                                    marker_color = pdata[\"color\"], text = pdata[\"names\"],\n",
    "                                                    hoverinfo = \"none\",textposition = \"outside\",\n",
    "                                                    texttemplate = \"%{x}<br>%{y:s}\",cliponaxis = False)],\n",
    "                                     layout = go.Layout(\n",
    "                                         font = {\"size\":20},\n",
    "                                         height = 700,\n",
    "                                         xaxis = {\"showline\":False,\"tickangle\":-90, \"visible\":False},\n",
    "                                         yaxis = {\"showline\":False, \"visible\":False},\n",
    "                                        title = title + \" For: \"+ str(i))))\n",
    "\n",
    "    fData = get_top_10(yvals)\n",
    "    \n",
    "    fig = go.Figure(\n",
    "    data = [go.Bar(x = fData[\"names\"], y = fData[\"pop\"],\n",
    "                   marker_color = fData[\"color\"],text = fData[\"names\"],\n",
    "                  hoverinfo = \"none\",textposition = \"outside\",\n",
    "                   texttemplate = \"%{x}<br>%{y:s}\",cliponaxis = False)],\n",
    "    layout=go.Layout(\n",
    "        title=title + \" For: \"+str(start_year),\n",
    "        font = {\"size\":20},\n",
    "        height = 700,\n",
    "        xaxis = {\"showline\":False,\"tickangle\":-90, \"visible\":False},\n",
    "        yaxis = {\"showline\":False, \"visible\":False},\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[dict(label=\"Play\",\n",
    "                          method=\"animate\",\n",
    "                          args=[None])])]\n",
    "    ),\n",
    "    frames=list(listOfFrames)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "make_bar_chart(data, \"type\", \"0\", \"39\",title = \"Distribution of types after each exchange\", frame_rate = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
