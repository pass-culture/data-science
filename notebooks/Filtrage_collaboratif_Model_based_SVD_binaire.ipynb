{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time \n",
    "import pickle\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from surprise import SVD, accuracy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgres://pass_culture:passq@localhost:5434/pass_culture?sslmode=prefer')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "########################## On récupère les offres notées par les utilisateurs ############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Offres achetées : 5\n",
    "#Offres achetées et pas consommées : 4 \n",
    "#Offres achetées et annulées : 3 \n",
    "#Offres mises en favoris : 2\n",
    "#Offres cliquées : 1 \n",
    "#Offres ignorées : 0 \n",
    "\n",
    "offres_avec_notes_0_5 = pd.read_csv('offres_avec_notes_0_5.csv', sep = '\\t') \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note 1 : offres mises en favoris, achetées et annnulées, achetées et pas consommées, achetées \n",
    "#Note 0 : offres ignorées ou juste cliquées\n",
    "offres_avec_notes_binaire = offres_avec_notes_0_5\n",
    "\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 1,'note'] = 0\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 2,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 3,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 4,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 5,'note'] = 1\n",
    "\n",
    "#On enregistre en csv \n",
    "offres_avec_notes_binaire.to_csv('offres_avec_notes_binaire.csv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Il y a', offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0].shape[0], 'notes 0')\n",
    "print('Il y a', offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1].shape[0], 'notes 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = offres_avec_notes_binaire['note'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / offres_avec_notes_binaire.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = 'Distribution de {} notes'.format(offres_avec_notes_binaire.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "#################################### Distribution par type d'offres ############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes par type \n",
    "notes_par_type = pd.DataFrame(columns = ['Type','Total'])\n",
    "notes_par_type['Type'] = offres_avec_notes_binaire['type'].value_counts().index\n",
    "notes_par_type['Total'] = offres_avec_notes_binaire['type'].value_counts().array\n",
    "notes_par_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes 0 par type\n",
    "note0_par_type = pd.DataFrame(columns = ['Type','Total_note0'])\n",
    "note0_par_type['Type'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0]['type'].value_counts().index\n",
    "note0_par_type['Total_note0'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0]['type'].value_counts().array\n",
    "note0_par_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes 1 par type\n",
    "note1_par_type = pd.DataFrame(columns = ['Type','Total_note1'])\n",
    "note1_par_type['Type'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]['type'].value_counts().index\n",
    "note1_par_type['Total_note1'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]['type'].value_counts().array\n",
    "note1_par_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne les trois tables\n",
    "notes_par_type = notes_par_type.merge(note0_par_type, left_on='Type', right_on='Type')\n",
    "notes_par_type = notes_par_type.merge(note1_par_type, left_on='Type', right_on='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul du pourcentage\n",
    "notes_par_type['pourcentage_note0'] = notes_par_type['Total_note0'] * 100 / notes_par_type['Total']\n",
    "notes_par_type['pourcentage_note1'] = notes_par_type['Total_note1'] * 100 / notes_par_type['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_par_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=notes_par_type['Type'], \n",
    "               y=notes_par_type['Total'],\n",
    "               name=\"Nombre de notes\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=notes_par_type['Type'],\n",
    "               y=notes_par_type['pourcentage_note1'],\n",
    "               name=\"%tage note 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#On ajoute le titre\n",
    "fig.update_layout(title_text='Distribution des notes par type')\n",
    "\n",
    "#Titre de l'axe x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Titre des axes y \n",
    "fig.update_yaxes(title_text=\"Nombre de notes\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Pourcentage dans la note 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "############################## Distribution par isVirtual : numerique / physique ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes par colonne \"isVirtual\"\n",
    "note_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total'])\n",
    "note_par_isVirtual['isVirtual'] = offres_avec_notes_binaire['isVirtual'].value_counts().index\n",
    "note_par_isVirtual['Total'] = offres_avec_notes_binaire['isVirtual'].value_counts().array\n",
    "note_par_isVirtual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes 0 par colonne \"isVirtual\"\n",
    "note0_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total_note0'])\n",
    "note0_par_isVirtual['isVirtual'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0]['isVirtual'].value_counts().index\n",
    "note0_par_isVirtual['Total_note0'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0]['isVirtual'].value_counts().array\n",
    "note0_par_isVirtual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes 1 par colonne \"isVirtual\"\n",
    "note1_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total_note1'])\n",
    "note1_par_isVirtual['isVirtual'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]['isVirtual'].value_counts().index\n",
    "note1_par_isVirtual['Total_note1'] = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]['isVirtual'].value_counts().array\n",
    "note1_par_isVirtual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne les trois tables\n",
    "note_par_isVirtual = note_par_isVirtual.merge(note0_par_isVirtual, left_on='isVirtual', right_on='isVirtual')\n",
    "note_par_isVirtual = note_par_isVirtual.merge(note1_par_isVirtual, left_on='isVirtual', right_on='isVirtual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On calcule les pourcentages\n",
    "note_par_isVirtual['pourcentage_note0'] = note_par_isVirtual['Total_note0'] * 100 / note_par_isVirtual['Total']\n",
    "note_par_isVirtual['pourcentage_note1'] = note_par_isVirtual['Total_note1'] * 100 / note_par_isVirtual['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_par_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=note_par_isVirtual['isVirtual'], \n",
    "               y=note_par_isVirtual['Total'],\n",
    "               name=\"Nombre de notes\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=note_par_isVirtual['isVirtual'],\n",
    "               y=note_par_isVirtual['pourcentage_note1'],\n",
    "               name=\"%tage note 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#On ajoute le titre\n",
    "fig.update_layout(title_text='Distribution des notes par isVirtual')\n",
    "\n",
    "#Titre de l'axe x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Titre des axes y \n",
    "fig.update_yaxes(title_text=\"Nombre de notes\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Pourcentage dans la note 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "########################################## SVD avant ré échantillonage #########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(offres_avec_notes_binaire[['user_id', 'offer_id', 'note']], reader)\n",
    "\n",
    "#On prend 75% pour l'entrainement et 25% pour le test\n",
    "trainset, testset = train_test_split(data, train_size=0.75, test_size=0.25)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "algo = SVD(n_factors=100)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'train_100_binaire_avant_reequilibrage.sav'\n",
    "pickle.dump(algo, open(filename, 'wb'))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'train_100_binaire_avant_reequilibrage.sav'\n",
    "algo = pickle.load(open(filename, 'rb')) \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'prediction_1000_binaire_avant_reequilibrage.sav'\n",
    "pickle.dump(predictions, open(filename, 'wb'))\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "filename = 'prediction_1000_binaire_avant_reequilibrage.sav'\n",
    "predictions = pickle.load(open(filename, 'rb')) \n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)\n",
    "pred.columns = ['user_id','offer_id', 'note', 'pred', 'details']\n",
    "del pred['details']\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pred['pred'].apply(round).value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / pred.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = 'Prédiction : Distribution de {} notes'.format(pred.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_avec_notes_binaire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On recupere les types des offres et la colonne isVirtual\n",
    "pred = pred.merge(offres_avec_notes_binaire, left_on=['user_id', 'offer_id','note'], \\\n",
    "                  right_on=['user_id', 'offer_id','note'])\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes par type \n",
    "note_par_type_pred = pd.DataFrame(columns = ['Type','Total'])\n",
    "note_par_type_pred['Type'] = pred['type'].value_counts().index\n",
    "note_par_type_pred['Total'] = pred['type'].value_counts().array\n",
    "note_par_type_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note0_par_type_pred = pd.DataFrame(columns = ['Type','Total_note0'])\n",
    "note0_par_type_pred['Type'] = pred[pred['note']==0]['type'].value_counts().index\n",
    "note0_par_type_pred['Total_note0'] = pred[pred['note']==0]['type'].value_counts().array\n",
    "note0_par_type_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note1_par_type_pred = pd.DataFrame(columns = ['Type','Total_note1'])\n",
    "note1_par_type_pred['Type'] = pred[pred['note']==1]['type'].value_counts().index\n",
    "note1_par_type_pred['Total_note1'] = pred[pred['note']==1]['type'].value_counts().array\n",
    "note1_par_type_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne les trois tables\n",
    "note_par_type_pred = note_par_type_pred.merge(note0_par_type_pred, left_on='Type', right_on='Type')\n",
    "note_par_type_pred = note_par_type_pred.merge(note1_par_type_pred, left_on='Type', right_on='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pourcentage des notes par type\n",
    "note_par_type_pred['pourcentage_note0'] = note_par_type_pred['Total_note0'] * 100 / note_par_type_pred['Total']\n",
    "note_par_type_pred['pourcentage_note1'] = note_par_type_pred['Total_note1'] * 100 / note_par_type_pred['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_par_type_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=note_par_type_pred['Type'], \n",
    "           y=note_par_type_pred['Total'],\n",
    "           name=\"Nombre de notes\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=note_par_type_pred['Type'],\n",
    "               y=note_par_type_pred['pourcentage_note1'],\n",
    "               name=\"%tage note 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#On ajoute le titre\n",
    "fig.update_layout(title_text='Prédiction : Distribution des notes par type')\n",
    "\n",
    "#Titre de l'axe x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Titre des axes y \n",
    "fig.update_yaxes(title_text=\"Nombre de notes\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Pourcentage dans la note 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de notes par colonne \"isVirtual\" \n",
    "note_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total'])\n",
    "note_par_isVirtual['isVirtual'] = pred['isVirtual'].value_counts().index\n",
    "note_par_isVirtual['Total'] = pred['isVirtual'].value_counts().array\n",
    "note_par_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note0_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total_note0'])\n",
    "note0_par_isVirtual['isVirtual'] = pred[pred['note']==0]['isVirtual'].value_counts().index\n",
    "note0_par_isVirtual['Total_note0'] = pred[pred['note']==0]['isVirtual'].value_counts().array\n",
    "note0_par_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note1_par_isVirtual = pd.DataFrame(columns = ['isVirtual','Total_note1'])\n",
    "note1_par_isVirtual['isVirtual'] = pred[pred['note']==1]['isVirtual'].value_counts().index\n",
    "note1_par_isVirtual['Total_note1'] = pred[pred['note']==1]['isVirtual'].value_counts().array\n",
    "note1_par_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne les trois tables\n",
    "note_par_isVirtual = note_par_isVirtual.merge(note0_par_isVirtual, left_on='isVirtual', right_on='isVirtual')\n",
    "note_par_isVirtual = note_par_isVirtual.merge(note1_par_isVirtual, left_on='isVirtual', right_on='isVirtual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pourcentage de notes pour la colonne \"isVirtual\"\n",
    "note_par_isVirtual['pourcentage_note0'] = note_par_isVirtual['Total_note0'] * 100 / note_par_isVirtual['Total']\n",
    "note_par_isVirtual['pourcentage_note1'] = note_par_isVirtual['Total_note1'] * 100 / note_par_isVirtual['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_par_isVirtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=note_par_isVirtual['isVirtual'], \n",
    "           y=note_par_isVirtual['Total'],\n",
    "           name=\"Nombre de notes\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=note_par_isVirtual['isVirtual'],\n",
    "               y=note_par_isVirtual['pourcentage_note1'],\n",
    "               name=\"%tage note 1\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "#On ajoute le titre\n",
    "fig.update_layout(title_text='Prédiction : Distribution des notes par isVirtual')\n",
    "\n",
    "#Titre de l'axe x \n",
    "fig.update_xaxes(title_text=\"Types\")\n",
    "\n",
    "#Titre des axes y \n",
    "fig.update_yaxes(title_text=\"Nombre de notes\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Pourcentage dans la note 1\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## METRIQUES ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "y_true = pred['note']\n",
    "y_pred = pred['pred'].apply(round)\n",
    "\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_pred), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Classes réelles'\n",
    "df_cm.columns.name = 'Classes prédites'\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "sn.set(font_scale=1.4)\n",
    "akws = {\"ha\": 'center',\"va\": 'center'}\n",
    "sn.heatmap(df_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", annot_kws=akws, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métriques\n",
    "y_true = pred['note']\n",
    "y_pred = pred['pred'].apply(round)\n",
    "\n",
    "print('accuracy = ', accuracy_score(y_true, y_pred))\n",
    "print('rappel = ', recall_score(y_true, y_pred))\n",
    "print('precision = ', precision_score(y_true, y_pred))\n",
    "print('F1 = ', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe ROC \n",
    "taux_faux_positifs = dict()\n",
    "taux_vrais_positifs = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 2\n",
    "\n",
    "y_true = pred['note']\n",
    "y_pred = pred['pred']\n",
    "\n",
    "for i in range(n_classes):\n",
    "    taux_faux_positifs[i], taux_vrais_positifs[i], _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc[i] = auc(taux_faux_positifs[i], taux_vrais_positifs[i])\n",
    "\n",
    "#Calcul de la courbe ROC \"micro\" et de l'AUC\n",
    "taux_faux_positifs[\"micro\"], taux_vrais_positifs[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(taux_faux_positifs[\"micro\"], taux_vrais_positifs[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.plot(taux_faux_positifs[\"micro\"], taux_vrais_positifs[\"micro\"], color='darkorange', lw=lw, label='AUC = %0.2f' % roc_auc[\"micro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cherche un compromis entre le taux de vrais positifs et le taux de faux positifs \n",
    "#Le seuil optimal serait lorsque taux_vrais_positifs est élevé et taux_faux_positifs est faible soit : \n",
    "#taux_vrais_positifs - (1-taux_faux_positifs) est zéro ou proche de zéro \n",
    "\n",
    "taux_faux_positifs, taux_vrais_positifs, thresholds = roc_curve(pred['note'], pred['pred'])\n",
    "roc_auc = auc(taux_faux_positifs, taux_vrais_positifs)\n",
    "\n",
    "i = np.arange(len(taux_vrais_positifs)) \n",
    "roc = pd.DataFrame({'taux_faux_positifs' : pd.Series(taux_faux_positifs, index=i), \\\n",
    "                    'taux_vrais_positifs' : pd.Series(taux_vrais_positifs, index = i), \\\n",
    "                    '1-taux_faux_positifs' : pd.Series(1-taux_faux_positifs, index = i), \\\n",
    "                    'tf' : pd.Series(taux_vrais_positifs - (1-taux_faux_positifs), index = i), \\\n",
    "                    'thresholds' : pd.Series(thresholds, index = i)})\n",
    "\n",
    "#Plot taux_vrais_positifs vs 1-taux_faux_positifs\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(roc['taux_vrais_positifs'], color = 'blue', label='TVP')\n",
    "pl.plot(roc['1-taux_faux_positifs'], color = 'red', label='1-taux_faux_positifs')\n",
    "pl.xlabel('1-Taux de faux positifs')\n",
    "pl.ylabel('Taux de vrais positifs')\n",
    "pl.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "#On affiche le point d'intersection\n",
    "roc = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On change les pred en fonction du seuil \n",
    "pred['pred_avec_seuil'] = pred['pred'].apply(lambda x: 1 if x > roc['thresholds'].values[0] else 0)\n",
    "\n",
    "# Print matrice de confusion\n",
    "y_true = pred['note']\n",
    "y_pred = pred['pred_avec_seuil']\n",
    "\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_pred), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Classes réelles'\n",
    "df_cm.columns.name = 'Classes prédites'\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "sn.set(font_scale=1.4)\n",
    "akws = {\"ha\": 'center',\"va\": 'center'}\n",
    "sn.heatmap(df_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", annot_kws=akws, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métriques \n",
    "y_true = pred['note']\n",
    "y_pred = pred['pred_avec_seuil']\n",
    "\n",
    "print('accuracy = ', accuracy_score(y_true, y_pred))\n",
    "print('rappel = ', recall_score(y_true, y_pred))\n",
    "print('precision = ', precision_score(y_true, y_pred))\n",
    "print('F1 = ', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################## \n",
    "################################## Recommandation avec seuil  #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On filtre les offres que l'on recommande de sorte à ne garder que les offres recommandables c'est à dire\n",
    "# - celle qui ont un seuil de prédiction supérieur au thresholds\n",
    "# - celles qui sont dans la table discovery_view\n",
    "# - celle qui sont dans un departement proche de l'utilisateur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On recupere la table des offres que l'on predit \n",
    "print(pred['offer_id'].nunique())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enlève les offres dont la prédiction est inferieur au seuil \n",
    "offres_recommandees_recommandables = pred[pred['pred_avec_seuil']==1]\n",
    "print(offres_recommandees_recommandables['offer_id'].nunique())\n",
    "offres_recommandees_recommandables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère toutes les offres recommandables\n",
    "discovery_view = pd.read_sql_query(\"\"\"SELECT id as offer_id FROM discovery_view\"\"\", connection)\n",
    "print(discovery_view['offer_id'].nunique())\n",
    "discovery_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne pour avoir que les offres qui sont dans discovery_view\n",
    "offres_recommandees_recommandables = offres_recommandees_recommandables.merge(discovery_view, \\\n",
    "                                                                              left_on='offer_id', \\\n",
    "                                                                              right_on='offer_id', \\\n",
    "                                                                             how='inner')\n",
    "print(offres_recommandees_recommandables['offer_id'].nunique())\n",
    "offres_recommandees_recommandables.drop_duplicates(inplace=True)\n",
    "offres_recommandees_recommandables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ajoute le code postal de l'utilisateur et celui de l'offre\n",
    "\n",
    "#on recupère le code postal des utilisateurs \n",
    "utilisateur_CP = pd.read_sql_query(\"\"\"SELECT \"user\".\"id\" as user_id, \"departementCode\" as user_CP\n",
    "                       FROM \"user\" \n",
    "                       \"\"\", connection)\n",
    "\n",
    "#on fusionne pour l'avoir dans notre table des offres recommandables\n",
    "offres_recommandees_recommandables = offres_recommandees_recommandables.merge(utilisateur_CP, \\\n",
    "                                                                                   left_on='user_id', \\\n",
    "                                                                                   right_on='user_id')\n",
    "\n",
    "#On recupère le code postal des offres \n",
    "offres_CP = pd.read_sql_query(\"\"\"SELECT \"offer\".\"id\" as offer_id, \"departementCode\" as offer_CP\n",
    "                       FROM \"offer\"\n",
    "                       LEFT JOIN venue ON offer.\"venueId\"=venue.id\n",
    "                       \"\"\", connection)\n",
    "\n",
    "offres_recommandees_recommandables = offres_recommandees_recommandables.merge(offres_CP, \\\n",
    "                                                                                   left_on='offer_id', \\\n",
    "                                                                                   right_on='offer_id')\n",
    "\n",
    "offres_recommandees_recommandables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée deux dataframe : un pour les offres physiques et un pour les offres numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_recommandees_recommandables_physique = offres_recommandees_recommandables.dropna()\n",
    "offres_recommandees_recommandables_physique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère la liste des départements \n",
    "departements_proches = {\n",
    "    '08': ['02', '08', '51', '55', '59'],\n",
    "    '22': ['22', '29', '35', '56'],\n",
    "    '25': ['21', '25', '39', '68', '70', '71', '90'],\n",
    "    '29': ['22', '35', '29', '56'],\n",
    "    '34': ['11', '12', '13', '30', '31', '34', '48', '66', '81', '84'],\n",
    "    '35': ['22', '29', '35', '44', '49', '50', '53', '56'],\n",
    "    '56': ['22', '29', '35', '44', '56'],\n",
    "    '58': ['03', '18', '21', '45', '58', '71', '89'],\n",
    "    '67': ['54', '55', '57', '67', '68', '88'],\n",
    "    '71': ['01', '03', '21', '39', '42', '58', '69', '71'],\n",
    "    '84': ['04', '07', '13', '26', '30', '83', '84'],\n",
    "    '93': ['75', '77', '78', '91', '92', '93', '94', '95'],\n",
    "    '94': ['75', '77', '78', '91', '92', '93', '94', '95'],\n",
    "    '97': ['97', '971', '972', '973'],\n",
    "    '973': ['97', '971', '972', '973'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On le transforme en dataframe\n",
    "keys = []\n",
    "values = []\n",
    "for key, value_list in departements_proches.items():\n",
    "    keys += [key] * len(value_list)\n",
    "    values += value_list\n",
    "    \n",
    "    \n",
    "departements_proches = pd.DataFrame({'user_cp' : keys, 'offer_cp' : values})\n",
    "departements_proches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne les deux tables pour ne garder que les offres qui sont dans un perimetre proche de l'utilisateur \n",
    "offres_recommandees_recommandables_physique = offres_recommandees_recommandables_physique.merge(departements_proches, \\\n",
    "                                                                             left_on=['user_cp','offer_cp'],\\\n",
    "                                                                             right_on=['user_cp','offer_cp'])\n",
    "offres_recommandees_recommandables_physique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On merge les deux tables des offres physique et numerique pour avoir nos offres recommandables \n",
    "offres_recommandees_recommandables = offres_recommandees_recommandables.merge(offres_recommandees_recommandables_physique, \\\n",
    "    right_on=['user_id', 'offer_id', 'note', 'pred', 'user_cp', 'offer_cp','type','isVirtual','pred_avec_seuil'], \\\n",
    "    left_on=['user_id', 'offer_id', 'note', 'pred', 'user_cp', 'offer_cp','type','isVirtual','pred_avec_seuil'], \\\n",
    "    how='left')\n",
    "print(offres_recommandees_recommandables['offer_id'].nunique())\n",
    "offres_recommandees_recommandables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Visualisation ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cherche les utilisateurs :\n",
    "# - les plus intéréssés par les offres (ceux qui ont mis le plus de \"note 1\")\n",
    "# - les moins intéréssés par les offres (ceux qui n'ont mis qu'une \"note 1\")\n",
    "offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On verifie que l'utilisateur n'est pas dans le trainset \n",
    "trainset.knows_user(63068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On visualise la recommandation que l'on fait à un utilisateur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_utilisateur = 61290\n",
    "\n",
    "prediction = pred[pred['pred_avec_seuil']==1]\n",
    "\n",
    "offres_recommandees_a_cet_utilisateur = prediction[prediction['user_id']==id_utilisateur]\n",
    "\n",
    "offres_recommandees_recommandables_a_cet_utilisateur = offres_recommandees_recommandables\\\n",
    "                                                    [offres_recommandees_recommandables['user_id']==id_utilisateur]\n",
    "\n",
    "interactions_dans_lapp = offres_avec_notes_binaire[offres_avec_notes_binaire['user_id']==id_utilisateur] \n",
    "interactions_dans_lapp_0 = interactions_dans_lapp[interactions_dans_lapp['note']==0]\n",
    "interactions_dans_lapp_1 =interactions_dans_lapp[interactions_dans_lapp['note']==1]\n",
    "\n",
    "\n",
    "#Nombre d'interactions de l'utilisateur dans l'app\n",
    "print(\"L'utilisateur a eu\", len(interactions_dans_lapp), \"interactions dans l'application, dont \",\\\n",
    "      len(interactions_dans_lapp_0), \"offres notées pas intéressantes et \", \\\n",
    "     len(interactions_dans_lapp_1), \"offres notées comme étant intéressantes\")\n",
    "\n",
    "#Offres qui interessent l'utilisateur \n",
    "print(\"L'utilisateur \", id_utilisateur, \"est intéréssé par \", \\\n",
    "      len(interactions_dans_lapp_1), \"offre(s) qui est/sont : \\n\",\\\n",
    "      interactions_dans_lapp_1, '\\n')\n",
    "\n",
    "#Les tyes d'offres qui interessent l'utilisateur \n",
    "print(\"Les types d'offres par ordre de préférence par cet utilisateur (en pourcentage): \")\n",
    "print((interactions_dans_lapp_1['type'].value_counts()) / \\\n",
    "      (interactions_dans_lapp_1['offer_id'].count()) * 100, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "#Les offres recommandées à l'utilisateur \n",
    "print(\"On lui recommande les\",len(offres_recommandees_a_cet_utilisateur), \"offre(s) suivante(s) :\")\n",
    "print(offres_recommandees_a_cet_utilisateur[['offer_id','type']], '\\n')\n",
    "\n",
    "#Les types d'offres que l'on recommande à l'utilisateur \n",
    "print(\"Les types d'offres recommandés pour cet utilisateur (en pourcentage): \")\n",
    "print((offres_recommandees_a_cet_utilisateur['type'].value_counts()) / \\\n",
    "      (len(offres_recommandees_a_cet_utilisateur)) * 100 ,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "#Les offres recommandées à l'utilisateur qui sont recommandables\n",
    "print(\"On lui recommande les\",len(offres_recommandees_recommandables_a_cet_utilisateur), \"offre(s) suivante(s) :\")\n",
    "print(offres_recommandees_recommandables_a_cet_utilisateur[['offer_id','type']], '\\n')\n",
    "\n",
    "#Les types d'offres que l'on recommande à l'utilisateur qui sont recommandables\n",
    "print(\"Les types d'offres recommandés pour cet utilisateur (en pourcentage): \")\n",
    "print((offres_recommandees_recommandables_a_cet_utilisateur['type'].value_counts()) / \\\n",
    "      (len(offres_recommandees_recommandables_a_cet_utilisateur)) * 100 ,'\\n')\n",
    "\n",
    "\n",
    "#Parmi les offres qu'on recommande, combien d'offres ont réellement été appréciées par l'utilisateur ? \n",
    "offres_communes = interactions_dans_lapp_1.merge(offres_recommandees_recommandables_a_cet_utilisateur,\\\n",
    "                left_on=['user_id', 'offer_id', 'type', 'isVirtual', 'note'], \\\n",
    "                right_on=['user_id', 'offer_id', 'type', 'isVirtual', 'note'])\n",
    "print(\"Parmi les\",len(offres_recommandees_recommandables_a_cet_utilisateur) ,\"offres que l'on a recommandé, il y en a\", offres_communes['offer_id'].nunique(), \"qu'il a \\\n",
    "réellement apprécié\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "########################################## Equilibrer les données #######################################################################\n",
    "############################ Plusieurs sous echantillonage donc plusieurs modèles #########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offres_avec_notes_0_5 = pd.read_csv('offres_avec_notes_0_5.csv', sep = '\\t') \n",
    "\n",
    "#Note 1 : offres mises en favoris, achetées et annnulées, achetées et pas consommées, achetées \n",
    "#Note 0 : offres ignorées ou juste cliquées\n",
    "offres_avec_notes_binaire = offres_avec_notes_0_5\n",
    "\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 1,'note'] = 0\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 2,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 3,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 4,'note'] = 1\n",
    "offres_avec_notes_binaire.loc[offres_avec_notes_binaire['note'] == 5,'note'] = 1\n",
    "\n",
    "#On enregistre en csv \n",
    "offres_avec_notes_binaire.to_csv('offres_avec_notes_binaire.csv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes0 = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==0]\n",
    "notes1 = offres_avec_notes_binaire[offres_avec_notes_binaire['note']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de 0 : ', notes0.shape[0])\n",
    "print('Nombre de 1 : ', notes1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On prend 10% des notes 1 que l'on ne va utiliser ni dans le train ni dans le test mais que l'on va utiliser dans\n",
    "#le test global \n",
    "testset1_global = notes1.sample(frac=0.1, random_state=1)\n",
    "\n",
    "#On cherche le nombre de notes 0 que l'on doit avoir pour avoir 97% de notes 0 et 3% de notes 1 \n",
    "size_testset0_global = testset1_global.shape[0] * 0.97 / 0.03\n",
    "\n",
    "#On met dans le trainset global le nombre de notes 0 necessaires\n",
    "testset0_global = notes0.sample(n=int(size_testset0_global), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_global = pd.concat([testset1_global,testset0_global])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = testset_global['note'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / testset_global.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = \"Distribution de {} notes dans le testset global\".format(testset_global.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On recupere toutes les offres restantes pour les notes 0 et 1 \n",
    "#Pour cela on concat notes 0 et testset0_global et on supprime tous les doublons (pareil pour 1)\n",
    "modele_note0 = pd.concat([notes0, testset0_global]).drop_duplicates(keep=False)\n",
    "modele_note1 = pd.concat([notes1, testset1_global]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cree nos 5 modeles en prenant \n",
    "#- Pour la note 1 : 25% de test et 75% de train \n",
    "#- Pour la note 0 : le meme nombre de notes pour le test que les 25% de la note 1 et un certain nombre de note 1 qui\n",
    "# doivent etre egale à 75% du dataset de train \n",
    "#--> Les trainsets de la note 0 et de la note 1 doivent etre egals\n",
    "#--> Le testset de la note 0 doit constitué 3% et le testset de la note 1 97% du testset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On prends de la note 1 : 75% pour le train et 25% pour le test pour les 5 modèles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset_note1_0, testset_note1_0 = train_test_split(modele_note1, test_size=0.25, train_size=0.75)\n",
    "trainset_note1_1, testset_note1_1 = train_test_split(modele_note1, test_size=0.25, train_size=0.75)\n",
    "trainset_note1_2, testset_note1_2 = train_test_split(modele_note1, test_size=0.25, train_size=0.75)\n",
    "trainset_note1_3, testset_note1_3 = train_test_split(modele_note1, test_size=0.25, train_size=0.75)\n",
    "trainset_note1_4, testset_note1_4 = train_test_split(modele_note1, test_size=0.25, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On calcule le pourcentage d'offres a prendre de la note 0 pour avoir 50 50 dans le train de 0 et de 1 \n",
    "train_size = (trainset_note1_0.shape[0] / modele_note0.shape[0])\n",
    "test_size = 1 - train_size\n",
    "\n",
    "trainset_note0_0, testset_note0_0 = train_test_split(modele_note0, test_size=test_size, train_size=train_size)\n",
    "trainset_note0_1, testset_note0_1 = train_test_split(modele_note0, test_size=test_size, train_size=train_size)\n",
    "trainset_note0_2, testset_note0_2 = train_test_split(modele_note0, test_size=test_size, train_size=train_size)\n",
    "trainset_note0_3, testset_note0_3 = train_test_split(modele_note0, test_size=test_size, train_size=train_size)\n",
    "trainset_note0_4, testset_note0_4 = train_test_split(modele_note0, test_size=test_size, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de 1 dans le train : ', trainset_note1_0.shape[0])\n",
    "print('Nombre de 0 dans le train : ', trainset_note0_0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On merge le trainset de 0 et de 1 \n",
    "trainset_modele_0 = pd.concat([trainset_note1_0, trainset_note0_0])\n",
    "trainset_modele_1 = pd.concat([trainset_note1_1, trainset_note0_1])\n",
    "trainset_modele_2 = pd.concat([trainset_note1_2, trainset_note0_2])\n",
    "trainset_modele_3 = pd.concat([trainset_note1_3, trainset_note0_3])\n",
    "trainset_modele_4 = pd.concat([trainset_note1_4, trainset_note0_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trainset_modele_0['note'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / trainset_modele_0.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = \"Distribution de {} notes dans le train\".format(trainset_modele_0.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On doit changer la proportion du testset de 0 pour avoir dans le testset 97 vs 3 ce qui n'est pas le cas ici \n",
    "print('On a :', testset_note1_0.shape[0], 'notes 1 dans le testset et cela doit representer 3%')\n",
    "print('Donc il nous faut', int(testset_note1_0.shape[0] * 0.97 / 0.03), 'notes 0 pour avoir 97%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne change pas le testset de 1 qui represente deja 3% des notes \n",
    "#On change testset de 0 pour avoir 97% des notes \n",
    "n = round(testset_note1_0.shape[0] * 0.97 / 0.03)\n",
    "\n",
    "testset_note0_0 = testset_note0_0.sample(n=n, random_state=1)\n",
    "testset_note0_1 = testset_note0_1.sample(n=n)\n",
    "testset_note0_2 = testset_note0_2.sample(n=n)\n",
    "testset_note0_3 = testset_note0_3.sample(n=n)\n",
    "testset_note0_4 = testset_note0_4.sample(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On merge le testset de 0 et de 1 \n",
    "testset_modele_0 = pd.concat([testset_note1_0, testset_note0_0])\n",
    "testset_modele_1 = pd.concat([testset_note1_1, testset_note0_1])\n",
    "testset_modele_2 = pd.concat([testset_note1_2, testset_note0_2])\n",
    "testset_modele_3 = pd.concat([testset_note1_3, testset_note0_3])\n",
    "testset_modele_4 = pd.concat([testset_note1_4, testset_note0_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = testset_modele_0['note'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / testset_modele_0.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "\n",
    "layout = dict(title = \"Distribution de {} notes dans le test de chaque modèle\".format(testset_modele_0.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On concat les trainset et les testset de chaque modèle\n",
    "data_modele_0 = pd.concat([trainset_modele_0, testset_modele_0])\n",
    "data_modele_1 = pd.concat([trainset_modele_1, testset_modele_1])\n",
    "data_modele_2 = pd.concat([trainset_modele_2, testset_modele_2])\n",
    "data_modele_3 = pd.concat([trainset_modele_3, testset_modele_3])\n",
    "data_modele_4 = pd.concat([trainset_modele_4, testset_modele_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "debut = time.time()\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "#On récupère les trainset et les testset de chaque modèle avec surpise\n",
    "data_modele_0 = Dataset.load_from_df(data_modele_0[['user_id', 'offer_id', 'note']], reader)\n",
    "data_modele_1 = Dataset.load_from_df(data_modele_1[['user_id', 'offer_id', 'note']], reader)\n",
    "data_modele_2 = Dataset.load_from_df(data_modele_2[['user_id', 'offer_id', 'note']], reader)\n",
    "data_modele_3 = Dataset.load_from_df(data_modele_3[['user_id', 'offer_id', 'note']], reader)\n",
    "data_modele_4 = Dataset.load_from_df(data_modele_4[['user_id', 'offer_id', 'note']], reader)\n",
    "\n",
    "#On récupère le testset global\n",
    "data_testset_global = Dataset.load_from_df(testset_global[['user_id', 'offer_id', 'note']], reader)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "debut = time.time()\n",
    "\n",
    "#Trainset et testset de chaque modèle\n",
    "trainset_0, testset_0 = train_test_split(data_modele_0, train_size = trainset_modele_0.shape[0], test_size = testset_modele_0.shape[0], shuffle=False)\n",
    "trainset_1, testset_1 = train_test_split(data_modele_1, train_size = trainset_modele_1.shape[0], test_size = testset_modele_1.shape[0], shuffle=False)\n",
    "trainset_2, testset_2 = train_test_split(data_modele_2, train_size = trainset_modele_2.shape[0], test_size = testset_modele_2.shape[0], shuffle=False)\n",
    "trainset_3, testset_3 = train_test_split(data_modele_3, train_size = trainset_modele_3.shape[0], test_size = testset_modele_3.shape[0], shuffle=False)\n",
    "trainset_4, testset_4 = train_test_split(data_modele_4, train_size = trainset_modele_4.shape[0], test_size = testset_modele_4.shape[0], shuffle=False)\n",
    "\n",
    "#Testset gloabl pour tous les modeles \n",
    "#Ici on met une note dans le trainset et tous le reste dans le testset car ce n'est pas possible de ne rien mettre\n",
    "#dans le trainset (il n'y a pas de trainsrt global de base)\n",
    "trainset_global, testset_global = train_test_split(data_testset_global, test_size=len(testset_global)-1, shuffle=False)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "algo_0 = SVD(n_factors=100)\n",
    "algo_1 = SVD(n_factors=100)\n",
    "algo_2 = SVD(n_factors=100)\n",
    "algo_3 = SVD(n_factors=100)\n",
    "algo_4 = SVD(n_factors=100)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Entrainement des 5 modeles\n",
    "algo_0.fit(trainset_0)\n",
    "algo_1.fit(trainset_1)\n",
    "algo_2.fit(trainset_2)\n",
    "algo_3.fit(trainset_3)\n",
    "algo_4.fit(trainset_4)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename0 = 'train_100_binaire_apres_reequilibrage_modele0.sav'\n",
    "filename1 = 'train_100_binaire_apres_reequilibrage_modele1.sav'\n",
    "filename2 = 'train_100_binaire_apres_reequilibrage_modele2.sav'\n",
    "filename3 = 'train_100_binaire_apres_reequilibrage_modele3.sav'\n",
    "filename4 = 'train_100_binaire_apres_reequilibrage_modele4.sav'\n",
    "\n",
    "pickle.dump(algo_0, open(filename0, 'wb'))\n",
    "pickle.dump(algo_1, open(filename1, 'wb'))\n",
    "pickle.dump(algo_2, open(filename2, 'wb'))\n",
    "pickle.dump(algo_3, open(filename3, 'wb'))\n",
    "pickle.dump(algo_4, open(filename4, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Predictions des 5 modeles avec leur testset\n",
    "predictions_0 = algo_0.test(testset_0)\n",
    "predictions_1 = algo_1.test(testset_1)\n",
    "predictions_2 = algo_2.test(testset_2)\n",
    "predictions_3 = algo_3.test(testset_3)\n",
    "predictions_4 = algo_4.test(testset_4)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = pd.DataFrame(predictions_0)\n",
    "pred_1 = pd.DataFrame(predictions_1)\n",
    "pred_2 = pd.DataFrame(predictions_2)\n",
    "pred_3 = pd.DataFrame(predictions_3)\n",
    "pred_4 = pd.DataFrame(predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0.columns = ['user_id','offer_id','note','pred_0','details']\n",
    "pred_1.columns = ['user_id','offer_id','note','pred_1','details']\n",
    "pred_2.columns = ['user_id','offer_id','note','pred_2','details']\n",
    "pred_3.columns = ['user_id','offer_id','note','pred_3','details']\n",
    "pred_4.columns = ['user_id','offer_id','note','pred_4','details']\n",
    "\n",
    "del pred_0['details']\n",
    "del pred_1['details']\n",
    "del pred_2['details']\n",
    "del pred_3['details']\n",
    "del pred_4['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename0 = 'prediction_100_binaire_apres_reequilibrage_modele0.sav'\n",
    "filename1 = 'prediction_100_binaire_apres_reequilibrage_modele1.sav'\n",
    "filename2 = 'prediction_100_binaire_apres_reequilibrage_modele2.sav'\n",
    "filename3 = 'prediction_100_binaire_apres_reequilibrage_modele3.sav'\n",
    "filename4 = 'prediction_100_binaire_apres_reequilibrage_modele4.sav'\n",
    "\n",
    "pickle.dump(pred_0, open(filename0, 'wb'))\n",
    "pickle.dump(pred_1, open(filename1, 'wb'))\n",
    "pickle.dump(pred_2, open(filename2, 'wb'))\n",
    "pickle.dump(pred_3, open(filename3, 'wb'))\n",
    "pickle.dump(pred_4, open(filename4, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Résultat pour un modèle. Changer les variables modele et pred pour visualiser les autres modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution des notes : prédiction\n",
    "modele = pred_0\n",
    "pred = modele['pred_0']\n",
    "\n",
    "data = pred.apply(round).value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / modele.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "layout = dict(title = \"Prédiction : Distribution de {} notes\".format(modele.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#Matrice de confusion\n",
    "y_true = modele['note']\n",
    "y_pred = pred.apply(round)\n",
    "\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_pred), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Classes réelles'\n",
    "df_cm.columns.name = 'Classes prédites'\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)\n",
    "akws = {\"ha\": 'center',\"va\": 'center'}\n",
    "sn.heatmap(df_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", annot_kws=akws, center=0)\n",
    "\n",
    "\n",
    "#Métriques\n",
    "y_true = modele['note']\n",
    "y_pred = pred.apply(round)\n",
    "\n",
    "print(\"accuracy = \", accuracy_score(y_true, y_pred))\n",
    "print('rappel = ', recall_score(y_true, y_pred))\n",
    "print('precision = ', precision_score(y_true, y_pred))\n",
    "print('F1 = ', f1_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "#Courbe ROC\n",
    "taux_faux_positif = dict()\n",
    "taux_vrais_positif = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 2\n",
    "\n",
    "y_true = modele['note']\n",
    "y_pred = pred\n",
    "\n",
    "for i in range(n_classes):\n",
    "    taux_faux_positif[i], taux_vrais_positif[i], _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc[i] = auc(taux_faux_positif[i], taux_vrais_positif[i])\n",
    "\n",
    "taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"], color='darkorange', lw=lw, label='AUC = %0.2f' % roc_auc[\"micro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test sur le testset_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = time.time()\n",
    "\n",
    "#Predictions des 5 modeles avec le testset global\n",
    "predictions_0 = algo_0.test(testset_global)\n",
    "predictions_1 = algo_1.test(testset_global)\n",
    "predictions_2 = algo_2.test(testset_global)\n",
    "predictions_3 = algo_3.test(testset_global)\n",
    "predictions_4 = algo_4.test(testset_global)\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = pd.DataFrame(predictions_0)\n",
    "pred_1 = pd.DataFrame(predictions_1)\n",
    "pred_2 = pd.DataFrame(predictions_2)\n",
    "pred_3 = pd.DataFrame(predictions_3)\n",
    "pred_4 = pd.DataFrame(predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0.columns = ['user_id','offer_id','note','pred_0','details']\n",
    "pred_1.columns = ['user_id','offer_id','note','pred_1','details']\n",
    "pred_2.columns = ['user_id','offer_id','note','pred_2','details']\n",
    "pred_3.columns = ['user_id','offer_id','note','pred_3','details']\n",
    "pred_4.columns = ['user_id','offer_id','note','pred_4','details']\n",
    "\n",
    "del pred_0['details']\n",
    "del pred_1['details']\n",
    "del pred_2['details']\n",
    "del pred_3['details']\n",
    "del pred_4['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fusionne toutes les tables\n",
    "pred_all = pred_0.merge(pred_1, right_on=['user_id','offer_id','note'], left_on=['user_id','offer_id','note'])\n",
    "pred_all = pred_all.merge(pred_2, right_on=['user_id','offer_id','note'], left_on=['user_id','offer_id','note'])\n",
    "pred_all = pred_all.merge(pred_3, right_on=['user_id','offer_id','note'], left_on=['user_id','offer_id','note'])\n",
    "pred_all = pred_all.merge(pred_4, right_on=['user_id','offer_id','note'], left_on=['user_id','offer_id','note'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all['pred_moyenne'] = (pred_all['pred_0'] + pred_all['pred_1'] + pred_all['pred_2'] + \\\n",
    "                            pred_all['pred_3'] + pred_all['pred_4']) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'prediction_global_100_binaire_apres_reequilibrage.sav'\n",
    "\n",
    "pickle.dump(pred_all, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all['pred_all_arrondie'] = pred_all['pred_moyenne'].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution des notes : prediction (testset sur l'ensemble des modeles)\n",
    "data = pred_all['pred_all_arrondie'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / pred_all.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "layout = dict(title = \"Prédiction : Distribution de {} notes\".format(pred_all.shape[0]),\n",
    "              xaxis = dict(title = 'Notes'),\n",
    "              yaxis = dict(title = \"Nombre de notes\"))\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#Matrice de confusion\n",
    "y_true = pred_all['note']\n",
    "y_pred = pred_all['pred_all_arrondie']\n",
    "\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_pred), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Classes réelles'\n",
    "df_cm.columns.name = 'Classes prédites'\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)\n",
    "akws = {\"ha\": 'center',\"va\": 'center'}\n",
    "sn.heatmap(df_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", annot_kws=akws, center=0)\n",
    "\n",
    "\n",
    "#Métriques\n",
    "y_true = pred_all['note']\n",
    "y_pred = pred_all['pred_all_arrondie']\n",
    "\n",
    "print(\"accuracy = \", accuracy_score(y_true, y_pred))\n",
    "print('rappel = ', recall_score(y_true, y_pred))\n",
    "print('precision = ', precision_score(y_true, y_pred))\n",
    "print('F1 = ', f1_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "#Courbe ROC \n",
    "taux_faux_positif = dict()\n",
    "taux_vrais_positif = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 2\n",
    "\n",
    "y_true = pred_all['note']\n",
    "y_pred = pred_all['pred_moyenne']\n",
    "\n",
    "for i in range(n_classes):\n",
    "    taux_faux_positif[i], taux_vrais_positif[i], _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc[i] = auc(taux_faux_positif[i], taux_vrais_positif[i])\n",
    "\n",
    "taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(taux_faux_positif[\"micro\"], taux_vrais_positif[\"micro\"], color='darkorange', lw=lw, label='AUC = %0.2f' % roc_auc[\"micro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cherche un compromis entre le taux de vrais positifs et le taux de faux positifs \n",
    "#Le seuil optimal serait lorsque taux_vrais_positifs est élevé et taux_faux_positifs est faible soit : \n",
    "#taux_vrais_positifs - (1-taux_faux_positifs) est zéro ou proche de zéro \n",
    "\n",
    "taux_faux_positifs, taux_vrais_positifs, thresholds = roc_curve(pred_all['note'], pred_all['pred_moyenne'])\n",
    "roc_auc = auc(taux_faux_positifs, taux_vrais_positifs)\n",
    "\n",
    "i = np.arange(len(taux_vrais_positifs)) \n",
    "roc = pd.DataFrame({'taux_faux_positifs' : pd.Series(taux_faux_positifs, index=i), \\\n",
    "                    'taux_vrais_positifs' : pd.Series(taux_vrais_positifs, index = i), \\\n",
    "                    '1-taux_faux_positifs' : pd.Series(1-taux_faux_positifs, index = i), \\\n",
    "                    'tf' : pd.Series(taux_vrais_positifs - (1-taux_faux_positifs), index = i), \\\n",
    "                    'thresholds' : pd.Series(thresholds, index = i)})\n",
    "\n",
    "#Plot taux_vrais_positifs vs 1-taux_faux_positifs\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(roc['taux_vrais_positifs'], color = 'blue', label='TVP')\n",
    "pl.plot(roc['1-taux_faux_positifs'], color = 'red', label='1-taux_faux_positifs')\n",
    "pl.xlabel('1-Taux de faux positifs')\n",
    "pl.ylabel('Taux de vrais positifs')\n",
    "pl.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "#On affiche le point d'intersection\n",
    "roc = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################\n",
    "############################## Facteurs latents ####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperer les ids des offres en dictionnaire\n",
    "debut = time.time()\n",
    "\n",
    "key_trainset = trainset.ir #Dict {id inner item : (id user,note)}\n",
    "dict_id_offers={}\n",
    "i=0\n",
    "for key in key_trainset.keys():\n",
    "    dict_id_offers[i]=trainset.to_raw_iid(key)\n",
    "    i=i+1\n",
    "#dict_id_offers\n",
    "\n",
    "#Recuperer les facteurs latents pour chaque offre \n",
    "#https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "offer_factor_latent = algo.qi\n",
    "offer_factor_latent = pd.DataFrame(offer_factor_latent)\n",
    "offer_factor_latent.rename(index=dict_id_offers, inplace=True)\n",
    "offer_factor_latent\n",
    "\n",
    "fin = time.time()\n",
    "temps = (fin - debut)/60\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trier les valeurs de chaque facteur par ordre décroissant\n",
    "for col in offer_factor_latent:\n",
    "    facteur = offer_factor_latent[col].sort_values(ascending=False)\n",
    "    facteur = pd.DataFrame(facteur)\n",
    "    print(facteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin1 = time.time()\n",
    "temps1 = (fin1 - debut1)/60\n",
    "print(temps1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
