{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(9001)\n",
    "from surprise import SVD, accuracy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "#pour avoir toujours les memes erreurs à chaque fois qu'on re exécute le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgres://pass_culture:passq@localhost:5434/pass_culture?sslmode=prefer')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_sql_query('SELECT id as user_id FROM \"user\" ORDER BY id', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer = pd.read_sql_query('SELECT id as offer_id FROM offer ORDER BY id', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id, freq_users = np.unique(user.user_id, return_counts=True)#user_id les id des users, freq_users les freq de chaque user\n",
    "offre_id, freq_offre = np.unique(offer.offer_id, return_counts=True)#offre_id les id des offres, freq_offre les freq de chaque offre\n",
    "n_users = len(user_id)\n",
    "n_offre = len(offre_id)\n",
    "print(\"Le nombre des utilisateurs est : \" + str(n_users) )\n",
    "print(\"Le nombre des offres est : \" + str(n_offre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On recupere la table des utilisateurs qui ont acheté des offres \n",
    "achete = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=True AND booking.\"isCancelled\"=False \\\n",
    "                       ORDER BY user_id', connection)\n",
    "achete['rate']=6\n",
    "achete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont acheté mais pas consommés des offres \n",
    "pas_consome = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=False AND booking.\"isCancelled\"=False', connection)\n",
    "pas_consome['rate']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont acheté et annulé des offres \n",
    "annule = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=False AND booking.\"isCancelled\"=True', connection)\n",
    "annule['rate']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont liké des offres \n",
    "mis_en_fav = pd.read_sql_query('SELECT \"userId\" as user_id, \"offerId\" as offer_id \\\n",
    "                          FROM favorite', connection)\n",
    "mis_en_fav['rate']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont clické sur des offres\n",
    "clic = pd.read_sql_query('SELECT \"userId\" AS user_id, \"offerId\" AS offer_id \\\n",
    "                          FROM recommendation \\\n",
    "                          WHERE \"isClicked\"=True', connection)\n",
    "clic['rate']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = pd.read_sql_query('SELECT \"userId\" AS user_id, \"offerId\" AS offer_id \\\n",
    "                          FROM recommendation \\\n",
    "                          WHERE \"isClicked\"=False', connection)\n",
    "ignore['rate']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([achete, pas_consome, annule, mis_en_fav, clic, ignore])\n",
    "result = result.sort_values('rate').drop_duplicates(subset=['user_id', 'offer_id'], keep='last')\n",
    "result.sort_values(by=['user_id'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "data = result['rate'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / result.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "# Create layout\n",
    "layout = dict(title = 'Distribution Of {} offers'.format(result.shape[0]),\n",
    "              xaxis = dict(title = 'Rating'),\n",
    "              yaxis = dict(title = 'Count'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 6))\n",
    "data = Dataset.load_from_df(result[['user_id', 'offer_id', 'rate']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.n_users \n",
    "trainset.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "offer_factor_latent = algo.qi\n",
    "offer_factor_latent = pd.DataFrame(offer_factor_latent)\n",
    "offer_factor_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return a list of ratings that can be used as a testset in the test() method.\n",
    "#The ratings are all the ratings that are in the trainset, i.e. all the ratings returned by the all_ratings() \n",
    "#generator. This is useful in cases where you want to to test your algorithm on the trainset.\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
