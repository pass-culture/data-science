{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(9001)\n",
    "#pour avoir toujours les memes erreurs à chaque fois qu'on re exécute le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgres://pass_culture:passq@localhost:5434/pass_culture?sslmode=prefer')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_sql_query('SELECT id as user_id FROM \"user\" ORDER BY id', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer = pd.read_sql_query('SELECT id as offer_id FROM offer ORDER BY id', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id, freq_users = np.unique(user.user_id, return_counts=True)#user_id les id des users, freq_users les freq de chaque user\n",
    "offre_id, freq_offre = np.unique(offer.offer_id, return_counts=True)#offre_id les id des offres, freq_offre les freq de chaque offre\n",
    "n_users = len(user_id)\n",
    "n_offre = len(offre_id)\n",
    "print(\"Le nombre des utilisateurs est : \" + str(n_users) )\n",
    "print(\"Le nombre des offres est : \" + str(n_offre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On recupere la table des utilisateurs qui ont acheté des offres \n",
    "achete = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=True AND booking.\"isCancelled\"=False \\\n",
    "                       ORDER BY user_id', connection)\n",
    "achete['rate']=6\n",
    "achete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont acheté mais pas consommés des offres \n",
    "pas_consome = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=False AND booking.\"isCancelled\"=False', connection)\n",
    "pas_consome['rate']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont acheté et annulé des offres \n",
    "annule = pd.read_sql_query('SELECT \"user\".id as user_id, offer.id as offer_id\\\n",
    "                       FROM \"booking\" \\\n",
    "                       INNER JOIN \"user\" ON \"user\".id=booking.\"userId\" \\\n",
    "                       INNER JOIN stock ON booking.\"stockId\"=stock.id \\\n",
    "                       INNER JOIN offer ON offer.id=stock.\"offerId\" \\\n",
    "                       WHERE booking.\"isUsed\"=False AND booking.\"isCancelled\"=True', connection)\n",
    "annule['rate']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont liké des offres \n",
    "mis_en_fav = pd.read_sql_query('SELECT \"userId\" as user_id, \"offerId\" as offer_id \\\n",
    "                          FROM favorite', connection)\n",
    "mis_en_fav['rate']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère les utilisateurs qui ont clické sur des offres\n",
    "clic = pd.read_sql_query('SELECT \"userId\" AS user_id, \"offerId\" AS offer_id \\\n",
    "                          FROM recommendation \\\n",
    "                          WHERE \"isClicked\"=True', connection)\n",
    "clic['rate']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = pd.read_sql_query('SELECT \"userId\" AS user_id, \"offerId\" AS offer_id \\\n",
    "                          FROM recommendation \\\n",
    "                          WHERE \"isClicked\"=False', connection)\n",
    "ignore['rate']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([achete, pas_consome, annule, mis_en_fav, clic, ignore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values('rate').drop_duplicates(subset=['user_id', 'offer_id'], keep='last')\n",
    "result.sort_values(by=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(result[[\"user_id\",\"offer_id\",\"rate\"]], test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si on a une grande sparsity (rareté des données), on ne va pas arriver à calculer la similarité entre \n",
    "#2 utilisateurs (par ex, si chaque utilisateur a aimé differentes offres comparé aux autres utilisateurs),\n",
    "#les modèles Model Based seront  plus efficace. Calculon alors la sparsity:\n",
    "sparsity = round(1.0 - len(result) / float(n_users*n_offre), 3)\n",
    "print ('The sparsity level of our data base is ' +  str(sparsity*100) + '%')\n",
    "print('Le pourcentage de sparsity est grand donc, on peut confirmer que les modèles Model Based seront les \\\n",
    "modèles plus efficaces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "train_data_matrix = coo_matrix((train_data['rate'], (train_data['user_id'], train_data['offer_id'])))\n",
    "train_data_matrix_by_row = train_data_matrix.tocsr()\n",
    "\n",
    "test_data_matrix = coo_matrix((test_data['rate'], (test_data['user_id'], test_data['offer_id'])))\n",
    "test_data_matrix_by_row = test_data_matrix.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcule de la cos similarity : (construction du modèle)\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "#offer_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):#prend\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating) #(type === array comme la var rating)\n",
    "        pred = mean_user_rating + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    \n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)]) \n",
    "        \n",
    "    x = np.zeros((n_users, n_offre))\n",
    "    for i in range(0, n_offre):\n",
    "        a=max(pred[:,i])\n",
    "        b=min(pred[:,i])\n",
    "        c=0\n",
    "        d=5\n",
    "        for j in range(0,n_users):\n",
    "            x[j,i]=(pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#la prédiction avec les differents modèle\n",
    "item_prediction = predict(train_data_matrix_by_row.T, item_similarity, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
